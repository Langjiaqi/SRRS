model_family: llama3-8b
model_path: /ljq/rtofu/results/rtofu_grposft_last_sft50/llama3-8b/forget01/GA3/seed_1001/epoch1_5e-06_FixRefTrue_maskTrue_1.0_1.0/1-2-3-4-5-6-7-8-9-10/unlearn_times_10/checkpoint-last
use_LoRA: ''
LoRA:
  r: 8
  alpha: 32
  dropout: 0.05
forget_data: tofu
data_path: data/tofu
split: forget01
task_id: 1
forget_loss: GA3
lr: 1.0e-05
num_epochs: 3
batch_size: 4
gradient_accumulation_steps: 1
forget_coeff: 1.0
regularization_coeff: 1.0
macro_epoch: 1
beta: 0.1
weight_decay: 0.01
fix_ref_model: false
mask: true
seed: 1001
unlearn_times: 10
save_checkpoint: false
overwrite_dir: false
save_steps: last
save_root: results/rtofu
save_dir: /ljq/rtofu/results/rtofu_grposft_last_sft50/llama3-8b/forget01/GA3/seed_1001/epoch1_5e-06_FixRefTrue_maskTrue_1.0_1.0/1-2-3-4-5-6-7-8-9-10/unlearn_times_10
ds_size: 300
eval_unlearn_step: 0
eval:
  model_family: ${..model_family}
  forget_loss: ${..forget_loss}
  do_sample: false
  data_path:
  - data/tofu
  - data/tofu
  - data/tofu
  - data/tofu
  split: ${..split}_perturbed
  split_list:
  - retain_perturbed
  - real_authors_perturbed
  - world_facts_perturbed
  - ${split}_perturbed
  eval_task:
  - eval_log
  - eval_real_author_wo_options
  - eval_real_world_wo_options
  - eval_log_forget
  question_key:
  - question
  - question
  - question
  - question
  answer_key:
  - answer
  - answer
  - answer
  - answer
  base_answer_key:
  - paraphrased_answer
  - answer
  - answer
  - paraphrased_answer
  perturbed_answer_key:
  - perturbed_answer
  - perturbed_answer
  - perturbed_answer
  - perturbed_answer
  generation:
    max_length: 1024
    max_new_tokens: null
  save_generated_text: true
  ds_size: ${..ds_size}
  overwrite: true
  use_pretrained: false
  batch_size: 5
