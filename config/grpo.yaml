model_family: llama3-8b
model_path: /ljq/rtofu/results/rtofu/llama3-8b/forget100/FINETUNE/seed_1001/epoch10_1e-05_FixRefFalse_maskTrue_1.0_1.0/1/unlearn_times_1/checkpoint-last
use_LoRA: false
LoRA:
  r: 8
  alpha: 32
  dropout: 0.05
forget_data: tofu
data_path: data/tofu
split: forget01
task_id: 7
forget_loss: GA3
lr: 5.0e-06
num_epochs: 1
batch_size: 1
gradient_accumulation_steps: 2
forget_coeff: 1.0
regularization_coeff: 1.0
macro_epoch: 1
beta: 0.1
weight_decay: 0.01
fix_ref_model: true
mask: true
seed: 1001
unlearn_times: 1
save_checkpoint: false
overwrite_dir: false
save_steps: last
save_root: results/rtofu_grposft_last_sft50
save_dir: ${save_root}/${model_family}/${split}/${forget_loss}/seed_${seed}/epoch${num_epochs}_${lr}_FixRef${fix_ref_model}_mask${mask}_${forget_coeff}_${regularization_coeff}
ds_size: 300
eval_unlearn_step: last
eval:
  model_family: ${..model_family}
  forget_loss: ${..forget_loss}
  do_sample: false
  data_path:
  - data/tofu
  - data/tofu
  - data/tofu
  - data/tofu
  split: ${..split}_perturbed
  split_list:
  - retain_perturbed
  - real_authors_perturbed
  - world_facts_perturbed
  - ${split}_perturbed
  eval_task:
  - eval_log
  - eval_real_author_wo_options
  - eval_real_world_wo_options
  - eval_log_forget
  question_key:
  - question
  - question
  - question
  - question
  answer_key:
  - answer
  - answer
  - answer
  - answer
  base_answer_key:
  - paraphrased_answer
  - answer
  - answer
  - paraphrased_answer
  perturbed_answer_key:
  - perturbed_answer
  - perturbed_answer
  - perturbed_answer
  - perturbed_answer
  generation:
    max_length: 1024
    max_new_tokens: null
  save_generated_text: true
  ds_size: ${..ds_size}
  overwrite: true
  use_pretrained: false
  batch_size: 5
use_grpo: true
grpo:
  num_generations: 6
  temperature: 1
  top_p: 0.95
  max_prompt_length: 256
  max_completion_length: 1024
  forget_reward_weight: 1.0
  quality_reward_weight: 0.3
