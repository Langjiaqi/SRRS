#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨ forget01.json æ•°æ®æµ‹è¯• metrics.py æ–‡ä»¶ä¸­çš„å‡½æ•°
"""

import os
import sys
import torch
import yaml
import json
from transformers import AutoTokenizer, AutoModelForCausalLM
from metrics.metrics import (
    read_jsonline, 
    token_entropy, 
    compute_token_entropy,
    eval_rouge_recall,
    eval_cosine_similarity,
    get_entailment_results,
    get_entailment_score,
    mask_non_answer_labels,
    get_batch_loss,
    TextDatasetQA,
    custom_data_collator,
    get_dataloader,
    get_all_evals
)

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = "config/tofu.yaml"
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config

def load_model_and_tokenizer(model_path):
    """åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨"""
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
    
    # æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        print(f"é”™è¯¯: æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
        return None, None
    
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModelForCausalLM.from_pretrained(
            model_path,
            torch_dtype=torch.float16,
            device_map="auto"
        )
        
        # è®¾ç½®ç‰¹æ®Štoken
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
            tokenizer.pad_token_id = tokenizer.eos_token_id
            
        print("æ¨¡å‹å’Œåˆ†è¯å™¨åŠ è½½æˆåŠŸ!")
        return model, tokenizer
        
    except Exception as e:
        print(f"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {e}")
        return None, None

def load_forget01_data():
    """åŠ è½½ forget01.json æ•°æ®"""
    print("\n=== åŠ è½½ forget01.json æ•°æ® ===")
    
    data_path = "/ljq/rtofu/data/tofu/forget01.json"
    
    if not os.path.exists(data_path):
        print(f"é”™è¯¯: æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        return None
    
    try:
        data = read_jsonline(data_path)
        print(f"æˆåŠŸåŠ è½½ {len(data)} æ¡æ•°æ®")
        
        # æ˜¾ç¤ºæ•°æ®ç»“æ„
        if data:
            print(f"æ•°æ®å­—æ®µ: {list(data[0].keys())}")
            print(f"ç¬¬ä¸€æ¡æ•°æ®ç¤ºä¾‹:")
            for key, value in data[0].items():
                if isinstance(value, str) and len(value) > 100:
                    print(f"  {key}: {value[:100]}...")
                else:
                    print(f"  {key}: {value}")
        
        return data
    except Exception as e:
        print(f"åŠ è½½æ•°æ®æ—¶å‡ºé”™: {e}")
        return None

def test_read_jsonline_with_forget01():
    """ä½¿ç”¨ forget01.json æµ‹è¯• read_jsonline å‡½æ•°"""
    print("\n=== æµ‹è¯• read_jsonline å‡½æ•° (ä½¿ç”¨ forget01.json) ===")
    
    data = load_forget01_data()
    if data is None:
        return False
    
    # åˆ†ææ•°æ®å†…å®¹
    print(f"\næ•°æ®ç»Ÿè®¡:")
    print(f"æ€»æ ·æœ¬æ•°: {len(data)}")
    
    # ç»Ÿè®¡é—®é¢˜é•¿åº¦
    question_lengths = [len(item.get('question', '')) for item in data]
    print(f"é—®é¢˜å¹³å‡é•¿åº¦: {sum(question_lengths) / len(question_lengths):.1f} å­—ç¬¦")
    
    # ç»Ÿè®¡ç­”æ¡ˆé•¿åº¦
    answer_lengths = [len(item.get('answer', '')) for item in data]
    print(f"ç­”æ¡ˆå¹³å‡é•¿åº¦: {sum(answer_lengths) / len(answer_lengths):.1f} å­—ç¬¦")
    
    # ç»Ÿè®¡coté•¿åº¦
    cot_lengths = [len(item.get('cot', '')) for item in data]
    print(f"COTå¹³å‡é•¿åº¦: {sum(cot_lengths) / len(cot_lengths):.1f} å­—ç¬¦")
    
    return True

def test_token_entropy_with_forget01(tokenizer):
    """ä½¿ç”¨ forget01.json æ•°æ®æµ‹è¯• token_entropy å‡½æ•°"""
    print("\n=== æµ‹è¯• token_entropy å‡½æ•° (ä½¿ç”¨ forget01.json) ===")
    
    data = load_forget01_data()
    if data is None:
        return False
    
    # é€‰æ‹©å‰5ä¸ªæ ·æœ¬è¿›è¡Œæµ‹è¯•
    test_samples = data[:5]
    
    # æå–é—®é¢˜å’Œç­”æ¡ˆ
    questions = [item.get('question', '') for item in test_samples]
    answers = [item.get('answer', '') for item in test_samples]
    cots = [item.get('cot', '') for item in test_samples]
    
    try:
        # æµ‹è¯•é—®é¢˜çš„token entropy
        print("è®¡ç®—é—®é¢˜çš„token entropy...")
        question_entropy = token_entropy(tokenizer, questions, normalize=True)
        print(f"é—®é¢˜token entropy: {question_entropy}")
        
        # æµ‹è¯•ç­”æ¡ˆçš„token entropy
        print("è®¡ç®—ç­”æ¡ˆçš„token entropy...")
        answer_entropy = token_entropy(tokenizer, answers, normalize=True)
        print(f"ç­”æ¡ˆtoken entropy: {answer_entropy}")
        
        # æµ‹è¯•COTçš„token entropy
        print("è®¡ç®—COTçš„token entropy...")
        cot_entropy = token_entropy(tokenizer, cots, normalize=True)
        print(f"COT token entropy: {cot_entropy}")
        
        # è®¡ç®—å¹³å‡ç†µ
        avg_question_entropy = sum(question_entropy['token_entropy']) / len(question_entropy['token_entropy'])
        avg_answer_entropy = sum(answer_entropy['token_entropy']) / len(answer_entropy['token_entropy'])
        avg_cot_entropy = sum(cot_entropy['token_entropy']) / len(cot_entropy['token_entropy'])
        
        print(f"\nå¹³å‡token entropy:")
        print(f"  é—®é¢˜: {avg_question_entropy:.4f}")
        print(f"  ç­”æ¡ˆ: {avg_answer_entropy:.4f}")
        print(f"  COT: {avg_cot_entropy:.4f}")
        
        return True
    except Exception as e:
        print(f"è®¡ç®—token entropyæ—¶å‡ºé”™: {e}")
        return False

def test_rouge_evaluation_with_forget01():
    """ä½¿ç”¨ forget01.json æ•°æ®æµ‹è¯• ROUGE è¯„ä¼°å‡½æ•°"""
    print("\n=== æµ‹è¯• ROUGE è¯„ä¼°å‡½æ•° (ä½¿ç”¨ forget01.json) ===")
    
    data = load_forget01_data()
    if data is None:
        return False
    
    # é€‰æ‹©å‰10ä¸ªæ ·æœ¬è¿›è¡Œæµ‹è¯•
    test_samples = data[:10]
    
    # æ¨¡æ‹Ÿç”Ÿæˆçš„ç­”æ¡ˆï¼ˆè¿™é‡Œä½¿ç”¨åŸå§‹ç­”æ¡ˆä½œä¸ºç”Ÿæˆç»“æœè¿›è¡Œæµ‹è¯•ï¼‰
    gen_outputs = [item.get('answer', '') for item in test_samples]
    ground_truths = [item.get('answer', '') for item in test_samples]
    
    try:
        rouge_scores = eval_rouge_recall(gen_outputs, ground_truths)
        
        print(f"ROUGE-1 Recall: {rouge_scores['rouge1_recall']}")
        print(f"ROUGE-L Recall: {rouge_scores['rougeL_recall']}")
        
        # è®¡ç®—å¹³å‡å€¼
        avg_rouge1 = sum(rouge_scores['rouge1_recall']) / len(rouge_scores['rouge1_recall'])
        avg_rougeL = sum(rouge_scores['rougeL_recall']) / len(rouge_scores['rougeL_recall'])
        
        print(f"\nå¹³å‡ROUGEåˆ†æ•°:")
        print(f"  ROUGE-1 Recall: {avg_rouge1:.4f}")
        print(f"  ROUGE-L Recall: {avg_rougeL:.4f}")
        
        return True
    except Exception as e:
        print(f"ROUGE è¯„ä¼°æ—¶å‡ºé”™: {e}")
        return False

def test_cosine_similarity_with_forget01():
    """ä½¿ç”¨ forget01.json æ•°æ®æµ‹è¯•ä½™å¼¦ç›¸ä¼¼åº¦å‡½æ•°"""
    print("\n=== æµ‹è¯•ä½™å¼¦ç›¸ä¼¼åº¦å‡½æ•° (ä½¿ç”¨ forget01.json) ===")
    
    data = load_forget01_data()
    if data is None:
        return False
    
    # é€‰æ‹©å‰10ä¸ªæ ·æœ¬è¿›è¡Œæµ‹è¯•
    test_samples = data[:10]
    
    # ä½¿ç”¨é—®é¢˜å’Œç­”æ¡ˆè¿›è¡Œç›¸ä¼¼åº¦æµ‹è¯•
    questions = [item.get('question', '') for item in test_samples]
    answers = [item.get('answer', '') for item in test_samples]
    
    try:
        similarity_scores = eval_cosine_similarity(questions, answers)
        
        print(f"ä½™å¼¦ç›¸ä¼¼åº¦åˆ†æ•°: {similarity_scores['cosine_similarity']}")
        
        # è®¡ç®—å¹³å‡å€¼
        avg_similarity = sum(similarity_scores['cosine_similarity']) / len(similarity_scores['cosine_similarity'])
        print(f"\nå¹³å‡ä½™å¼¦ç›¸ä¼¼åº¦: {avg_similarity:.4f}")
        
        return True
    except Exception as e:
        print(f"è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦æ—¶å‡ºé”™: {e}")
        return False

def test_dataset_loading_with_forget01(config, tokenizer):
    """ä½¿ç”¨ forget01.json æµ‹è¯•æ•°æ®é›†åŠ è½½"""
    print("\n=== æµ‹è¯•æ•°æ®é›†åŠ è½½ (ä½¿ç”¨ forget01.json) ===")
    
    try:
        # åŠ è½½forget01æ•°æ®é›†
        dataset = TextDatasetQA(
            folder="data/tofu",
            tokenizer=tokenizer,
            model_family=config['model_family'],
            max_length=config['eval']['generation']['max_length'],
            split="forget01",
            question_key="question",
            answer_key="answer"
        )
        
        print(f"æ•°æ®é›†å¤§å°: {len(dataset)}")
        
        # æµ‹è¯•è·å–å‡ ä¸ªæ ·æœ¬
        if len(dataset) > 0:
            print(f"æ ·æœ¬æ ¼å¼: input_ids shape: {dataset[0][0].shape}, labels shape: {dataset[0][1].shape}")
            
            # æ˜¾ç¤ºå‰3ä¸ªæ ·æœ¬çš„è¯¦ç»†ä¿¡æ¯
            for i in range(min(3, len(dataset))):
                sample = dataset[i]
                print(f"\næ ·æœ¬ {i+1}:")
                print(f"  input_ids shape: {sample[0].shape}")
                print(f"  labels shape: {sample[1].shape}")
                print(f"  attention_mask shape: {sample[2].shape}")
                
                # è§£ç æ˜¾ç¤ºéƒ¨åˆ†å†…å®¹
                decoded = tokenizer.decode(sample[0][0][:50], skip_special_tokens=True)
                print(f"  è§£ç å†…å®¹ (å‰50ä¸ªtoken): {decoded[:100]}...")
        
        return True
    except Exception as e:
        print(f"æ•°æ®é›†åŠ è½½æ—¶å‡ºé”™: {e}")
        return False

def test_dataloader_with_forget01(config, tokenizer):
    """æµ‹è¯•æ•°æ®åŠ è½½å™¨"""
    print("\n=== æµ‹è¯•æ•°æ®åŠ è½½å™¨ (ä½¿ç”¨ forget01.json) ===")
    
    try:
        # ä½¿ç”¨get_dataloaderå‡½æ•°
        eval_dataloader, base_eval_dataloader, perturb_dataloader = get_dataloader(
            cfg=config,
            eval_task="eval_log",
            tokenizer=tokenizer,
            folder="data/tofu",
            split="forget01",
            question_key="question",
            answer_key="answer",
            base_answer_key="answer",
            perturbed_answer_key="answer"
        )
        
        print(f"eval_dataloader æ‰¹æ¬¡æ•°: {len(eval_dataloader)}")
        print(f"base_eval_dataloader æ‰¹æ¬¡æ•°: {len(base_eval_dataloader)}")
        print(f"perturb_dataloader æ‰¹æ¬¡æ•°: {len(perturb_dataloader)}")
        
        # æµ‹è¯•è·å–ä¸€ä¸ªæ‰¹æ¬¡
        for batch in eval_dataloader:
            input_ids, labels, attention_mask = batch
            print(f"\næ‰¹æ¬¡ä¿¡æ¯:")
            print(f"  input_ids shape: {input_ids.shape}")
            print(f"  labels shape: {labels.shape}")
            print(f"  attention_mask shape: {attention_mask.shape}")
            break
        
        return True
    except Exception as e:
        print(f"æ•°æ®åŠ è½½å™¨æµ‹è¯•æ—¶å‡ºé”™: {e}")
        return False

def test_mask_non_answer_labels_with_forget01(tokenizer):
    """ä½¿ç”¨ forget01.json æ•°æ®æµ‹è¯• mask_non_answer_labels å‡½æ•°"""
    print("\n=== æµ‹è¯• mask_non_answer_labels å‡½æ•° (ä½¿ç”¨ forget01.json) ===")
    
    data = load_forget01_data()
    if data is None:
        return False
    
    try:
        # åˆ›å»ºæ¨¡æ‹Ÿçš„labelsï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
        batch_size = 2
        seq_len = 100
        labels = torch.randint(0, 1000, (batch_size, seq_len))
        
        masked_labels = mask_non_answer_labels(labels, tokenizer)
        
        print(f"åŸå§‹labels shape: {labels.shape}")
        print(f"Masked labels shape: {masked_labels.shape}")
        
        # ç»Ÿè®¡è¢«maskçš„tokenæ•°é‡
        masked_count = (masked_labels == -100).sum().item()
        total_count = masked_labels.numel()
        print(f"è¢«maskçš„tokenæ¯”ä¾‹: {masked_count}/{total_count} ({masked_count/total_count*100:.1f}%)")
        
        return True
    except Exception as e:
        print(f"Mask labelsæ—¶å‡ºé”™: {e}")
        return False

def test_batch_loss_with_forget01():
    """ä½¿ç”¨ forget01.json æ•°æ®æµ‹è¯• get_batch_loss å‡½æ•°"""
    print("\n=== æµ‹è¯• get_batch_loss å‡½æ•° (ä½¿ç”¨ forget01.json) ===")
    
    try:
        # åˆ›å»ºæ¨¡æ‹Ÿçš„è¾“å‡ºå’Œæ ‡ç­¾
        batch_size, seq_len, vocab_size = 2, 100, 32000  # ä½¿ç”¨æ›´çœŸå®çš„å‚æ•°
        output = torch.randn(batch_size, seq_len, vocab_size)
        labels = torch.randint(0, vocab_size, (batch_size, seq_len))
        
        # è®¾ç½®ä¸€äº›-100æ ‡ç­¾ï¼ˆæ¨¡æ‹Ÿpaddingï¼‰
        labels[0, :20] = -100
        labels[1, :15] = -100
        
        loss = get_batch_loss(output, labels)
        
        print(f"è¾“å‡ºshape: {output.shape}")
        print(f"æ ‡ç­¾shape: {labels.shape}")
        print(f"æŸå¤±shape: {loss.shape}")
        print(f"æŸå¤±å€¼: {loss}")
        print(f"å¹³å‡æŸå¤±: {loss.mean().item():.4f}")
        
        return True
    except Exception as e:
        print(f"è®¡ç®—batch lossæ—¶å‡ºé”™: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹ä½¿ç”¨ forget01.json æ•°æ®æµ‹è¯• metrics.py ä¸­çš„å‡½æ•°...")
    
    # åŠ è½½é…ç½®
    config = load_config()
    print(f"é…ç½®åŠ è½½æˆåŠŸ: model_family={config['model_family']}")
    
    # æ¨¡å‹è·¯å¾„
    model_path = "/ljq/rtofu/results/rtofu/llama3-8b/forget01/GA1/seed_1001/epoch3_1e-05_FixRefFalse_maskTrue_1.0_1.0/1/unlearn_times_1/checkpoint-last"
    
    # åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
    model, tokenizer = load_model_and_tokenizer(model_path)
    if model is None or tokenizer is None:
        print("æ— æ³•åŠ è½½æ¨¡å‹ï¼Œé€€å‡ºæµ‹è¯•")
        return
    
    # è¿è¡Œå„ç§æµ‹è¯•
    test_results = []
    
    test_results.append(("read_jsonline_with_forget01", test_read_jsonline_with_forget01()))
    test_results.append(("token_entropy_with_forget01", test_token_entropy_with_forget01(tokenizer)))
    test_results.append(("rouge_evaluation_with_forget01", test_rouge_evaluation_with_forget01()))
    test_results.append(("cosine_similarity_with_forget01", test_cosine_similarity_with_forget01()))
    test_results.append(("dataset_loading_with_forget01", test_dataset_loading_with_forget01(config, tokenizer)))
    test_results.append(("dataloader_with_forget01", test_dataloader_with_forget01(config, tokenizer)))
    test_results.append(("mask_non_answer_labels_with_forget01", test_mask_non_answer_labels_with_forget01(tokenizer)))
    test_results.append(("batch_loss_with_forget01", test_batch_loss_with_forget01()))
    
    # æ‰“å°æµ‹è¯•ç»“æœæ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•ç»“æœæ€»ç»“:")
    print("="*60)
    
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"{test_name:35} : {status}")
        if result:
            passed += 1
    
    print(f"\næ€»è®¡: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡äº†!")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
    
    print("\næ³¨æ„: è¿™ä¸ªæµ‹è¯•ä½¿ç”¨äº† forget01.json çš„çœŸå®æ•°æ®ï¼Œ")
    print("åŒ…å«äº†å®é™…çš„é—®ç­”å¯¹å’Œæ€ç»´é“¾æ•°æ®ï¼Œå¯ä»¥æ›´å¥½åœ°éªŒè¯å‡½æ•°çš„å®é™…æ•ˆæœã€‚")

if __name__ == "__main__":
    main()